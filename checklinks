#!/bin/bash
set -e


# Check for dead links
#
# Fail when website links to any broken urls.
# Gather all internal pages first,
# then check their linked ressources.


domain="https://jorin.me"
common="--spider -r --no-verbose --no-directories -w0.1 -T60 --tries 3"
firefox="Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:54.0) Gecko/20100101 Firefox/54.0"
check="--level 1 --span-hosts --execute robots=off -U \"$firefox\""

wget $common $domain 2>&1 | grep -o "$domain[^ ]*" | xargs wget $common $check
