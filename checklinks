#!/bin/bash
set -eux


# Check for dead links
#
# Fail when website links to any broken urls.
# Gather all internal pages first,
# then check their linked ressources.


domain="jorin.me"
common="
  --spider
  --recursive
  --no-verbose
  --no-directories
  --wait 0.1
  --timeout 60
  --tries 3
  --user-agent linkchecker
"
extern="
  --level 1
  --span-hosts
  --execute robots=off
  --exclude-domains $domain
"

wget $common $domain 2>&1 | grep -o "$domain[^ ]*" | xargs wget $common $extern
